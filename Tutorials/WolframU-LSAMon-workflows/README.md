# Wolfram U Latent Semantic Analysis workflows lectures

## In brief

The lectures are to be recorded through Wolfram University (Wolfram U) in December 2019 and January-February 2020.


## The lectures (as live-coding sessions)

1. Overview Latent Semantic Analysis (LSA) typical problems and basic workflows. 
   Answering preliminary anticipated questions.
   
   - What are the typical applications of LSA?   
   - Why use LSA?     
   - What it the fundamental philosophical or scientific assumption for LSA?   
   - What is the most important and/or fundamental step of LSA?   
   - What is the difference between LSA and Latent Semantic Indexing (LSI)?   
   - What are the alternatives?
     - Using Neural Networks instead?   
   - How is LSA used to derive similarities between two given texts?   
   - How is LSA used to evaluate the proximity of phrases?
     (That have different words, but close semantic meaning.)   
   - How the main dimension reduction methods compare?
   
2. LSA for document collections.

   - Representation of the documents.
   - Dimension reduction methods comparisons.
   - Representation of unseen documents.
   
3. LSA for image collections.

   - Representation of the documents.
   - Dimension reduction methods comparisons.
   - Representation of unseen documents.
   
4. Further use cases.

   - LSA based image classification.
   - LSA for time series collections.
