# Presentations

## WTC-2019

***TBD***...

## UseR!-2020

Here is the (extended) abstract the *proposed* presentation:

- ["How to simplify Machine learning workflows specifications?"](https://htmlpreview.github.io/?https://github.com/antononcube/SimplifiedMachineLearningWorkflows-book/blob/master/Presentations/UseR!-2020/How-to-simplify-ML-workflows-specifications.nb.html). 

Versions:
[HTML](https://htmlpreview.github.io/?https://github.com/antononcube/SimplifiedMachineLearningWorkflows-book/blob/master/Presentations/UseR!-2020/How-to-simplify-ML-workflows-specifications.nb.html), 
[Rmd](./UseR!-2020/How-to-simplify-ML-workflows-specifications.Rmd).
 
Here is the *submitted* abstract:

> In this presentation we discuss a systematic approach of software development
that gives us the ability to rapidly specify Machine Learning (ML) computations
using both programming Domain Specific Languages (DSL's) and natural language commands.
We present in detail the selection of programming paradigms, languages, and packages.

>A central topic of the presentation is the transformation of sequences of natural 
commands into corresponding DSL pipelines for ML computations. 

>We use monadic programming and code generation for implementation of ML packages.
We use Raku (Perl 6) for grammar specifications, parsers generation, and interpreters.

>Numerous examples are used based on ML packages written in R
and English-based grammar rules. We look into code generation 
of ML workflows for supervised learning, time series analysis, latent semantic analysis, 
and recommendations. We show how with the same natural commands pipelines in other
programming languages can be generated.

>Finally we discuss the extensions of the presented approach to (1) handling wrong commands and
spelling mistakes, (2) using multiple natural languages, and (3) making conversational agents.